{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **(Data Collection)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/codeinstitute/cherry-leaves\n",
            "License(s): unknown\n",
            "Downloading cherry-leaves.zip to /Users/azuki/cherry-leaf-disease-control/inputs/mildew_dataset\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 55.0M/55.0M [00:04<00:00, 12.7MB/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55.0M/55.0M [00:04<00:00, 11.8MB/s]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹Kaggleãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ‘ã‚¹\n",
        "KaggleDatasetPath = \"codeinstitute/cherry-leaves\"\n",
        "\n",
        "# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä¿å­˜å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆãƒ•ãƒ«ãƒ‘ã‚¹ï¼‰\n",
        "DestinationFolder = os.path.join(os.getcwd(), \"inputs/mildew_dataset\")\n",
        "\n",
        "# ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ\n",
        "os.makedirs(DestinationFolder, exist_ok=True)\n",
        "\n",
        "# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦è§£å‡\n",
        "!kaggle datasets download -d {KaggleDatasetPath} -p {DestinationFolder} --unzip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“‚ Healthy: ç”»åƒ 2104 æš, éç”»åƒ 0 æš å‰Šé™¤æ¸ˆã¿ âœ…\n",
            "ğŸ“‚ Infected: ç”»åƒ 2104 æš, éç”»åƒ 0 æš å‰Šé™¤æ¸ˆã¿ âœ…\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "\n",
        "def remove_non_image_files(my_data_dir):\n",
        "    \"\"\"\n",
        "    æŒ‡å®šã•ã‚ŒãŸãƒ•ã‚©ãƒ«ãƒ€å†…ã®ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ä»¥å¤–ã‚’å‰Šé™¤ã™ã‚‹\n",
        "    \"\"\"\n",
        "    image_extensions = (\".png\", \".jpg\", \".jpeg\")\n",
        "\n",
        "    for folder in os.listdir(my_data_dir):\n",
        "        folder_path = os.path.join(my_data_dir, folder)\n",
        "        if os.path.isdir(folder_path):\n",
        "            files = os.listdir(folder_path)\n",
        "            non_image_count = 0\n",
        "            image_count = 0\n",
        "\n",
        "            for file in files:\n",
        "                file_path = os.path.join(folder_path, file)\n",
        "\n",
        "                # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã§ã¯ãªã„ & ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹å ´åˆã®ã¿å‰Šé™¤\n",
        "                if os.path.isfile(file_path) and not file.lower().endswith(\n",
        "                    image_extensions\n",
        "                ):\n",
        "                    try:\n",
        "                        os.remove(file_path)  # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤\n",
        "                        print(f\"ğŸ—‘ï¸ å‰Šé™¤: {file_path}\")\n",
        "                        non_image_count += 1\n",
        "                    except Exception as e:\n",
        "                        print(f\"âš ï¸ å‰Šé™¤å¤±æ•—: {file_path} â†’ {e}\")\n",
        "                else:\n",
        "                    image_count += 1\n",
        "\n",
        "            print(\n",
        "                f\"ğŸ“‚ {folder}: ç”»åƒ {image_count} æš, éç”»åƒ {non_image_count} æš å‰Šé™¤æ¸ˆã¿ âœ…\"\n",
        "            )\n",
        "\n",
        "\n",
        "# ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Ÿè¡Œ\n",
        "remove_non_image_files(\"inputs/mildew_dataset/cherry-leaves\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†ï¼\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "dataset_path = \"inputs/mildew_dataset/cherry-leaves\"\n",
        "\n",
        "# âœ… ä¸è¦ãªãƒ•ã‚©ãƒ«ãƒ€ (.ipynb_checkpoints) ã‚’å‰Šé™¤\n",
        "for root, dirs, files in os.walk(dataset_path):\n",
        "    for dir_name in dirs:\n",
        "        if dir_name == \".ipynb_checkpoints\":\n",
        "            shutil.rmtree(os.path.join(root, dir_name))\n",
        "            print(f\"ğŸ—‘ï¸ å‰Šé™¤: {os.path.join(root, dir_name)}\")\n",
        "\n",
        "print(\"âœ… ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†ï¼\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ç•°å¸¸ãªãƒ•ã‚©ãƒ«ãƒ€ã¯å­˜åœ¨ã—ã¾ã›ã‚“ã§ã—ãŸ\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "\n",
        "# ç•°å¸¸ãªãƒ•ã‚©ãƒ«ãƒ€ãŒå­˜åœ¨ã™ã‚‹å ´åˆã«å‰Šé™¤\n",
        "error_path = \"inputs/mildew_dataset/cherry-leaves/test/test\"\n",
        "if os.path.exists(error_path):\n",
        "    shutil.rmtree(error_path)\n",
        "    print(f\"âœ… ç•°å¸¸ãªãƒ•ã‚©ãƒ«ãƒ€ã‚’å‰Šé™¤ã—ã¾ã—ãŸ: {error_path}\")\n",
        "else:\n",
        "    print(\"âœ… ç•°å¸¸ãªãƒ•ã‚©ãƒ«ãƒ€ã¯å­˜åœ¨ã—ã¾ã›ã‚“ã§ã—ãŸ\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import joblib\n",
        "\n",
        "def split_train_validation_test_images(my_data_dir, train_set_ratio, validation_set_ratio, test_set_ratio):    \n",
        "    \"\"\"\n",
        "    Split the dataset into training, validation, and test sets.\n",
        "    \"\"\"\n",
        "    # Validate that the sum of train, validation, and test ratios equals 1.0\n",
        "    if train_set_ratio + validation_set_ratio + test_set_ratio!= 1.0:\n",
        "        print(\"Error: train_set_ratio + validation_set_ratio + test_set_ratio should sum to 1.0\")\n",
        "        return\n",
        "\n",
        "    # Get the class labels in the dataset directory\n",
        "    labels = os.listdir(my_data_dir)  \n",
        "\n",
        "    # Create 'train', 'validation', and 'test' folders with class subfolders\n",
        "    for folder in ['train', 'validation', 'test']:\n",
        "        for label in labels:\n",
        "            os.makedirs(name=os.path.join(my_data_dir, folder, label), exist_ok=True)\n",
        "\n",
        "    # Iterate through each class label\n",
        "    for label in labels:\n",
        "        # Get the list of files in the current class label directory\n",
        "        files = os.listdir(os.path.join(my_data_dir, label))\n",
        "        random.shuffle(files)\n",
        "        # Calculate the number of files for train, validation, and test sets\n",
        "        train_set_files_qty = int(len(files) * train_set_ratio)\n",
        "        validation_set_files_qty = int(len(files) * validation_set_ratio)\n",
        "\n",
        "        count = 1\n",
        "        for file_name in files:\n",
        "            if count <= train_set_files_qty:\n",
        "                # Move the file to the 'train' set\n",
        "                shutil.move(os.path.join(my_data_dir, label, file_name),\n",
        "                            os.path.join(my_data_dir, 'train', label, file_name))\n",
        "\n",
        "            elif count <= (train_set_files_qty + validation_set_files_qty):\n",
        "                # Move the file to the 'validation' set\n",
        "                shutil.move(\n",
        "                    os.path.join(my_data_dir, label, file_name),\n",
        "                    os.path.join(my_data_dir, \"validation\", label, file_name),\n",
        "                )\n",
        "            else:\n",
        "                # Move the file to the 'test' set\n",
        "                shutil.move(\n",
        "                    os.path.join(my_data_dir, label, file_name),\n",
        "                    os.path.join(my_data_dir, \"test\", label, file_name),\n",
        "                )\n",
        "\n",
        "            count += 1\n",
        "        # Remove the original class directory after all files are moved\n",
        "        os.rmdir(os.path.join(my_data_dir, label))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "!which python\n",
        "print(sys.executable)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting joblib\n",
            "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
            "Installing collected packages: joblib\n",
            "Successfully installed joblib-1.4.2\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!{sys.executable} -m pip install joblib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "dataset_path = \"inputs/mildew_dataset/cherry-leaves\"\n",
        "\n",
        "# ğŸ”¥ ã™ã§ã«ã‚ã‚‹ train, validation, test ã‚’å‰Šé™¤\n",
        "for folder in [\"train\", \"validation\", \"test\"]:\n",
        "    folder_path = os.path.join(dataset_path, folder)\n",
        "    if os.path.exists(folder_path):\n",
        "        shutil.rmtree(folder_path)  # ãƒ•ã‚©ãƒ«ãƒ€ã”ã¨å‰Šé™¤\n",
        "        print(f\"ğŸ—‘ï¸ å‰Šé™¤: {folder_path}\")\n",
        "\n",
        "print(\"âœ… æ—¢å­˜ã® train, validation, test ã‚’å‰Šé™¤ã—ã¾ã—ãŸï¼\")\n",
        "\n",
        "# ğŸ”„ ãã®å¾Œã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’åˆ†å‰²\n",
        "split_train_validation_test_images(\n",
        "    my_data_dir=dataset_path,\n",
        "    train_set_ratio=0.7,\n",
        "    validation_set_ratio=0.1,\n",
        "    test_set_ratio=0.2,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "sets = [\"train\", \"test\", \"validation\"]\n",
        "labels = [\"Healthy\", \"Infected\"]\n",
        "\n",
        "for set_name in sets:\n",
        "    for label in labels:\n",
        "        path = f\"inputs/mildew_dataset/cherry-leaves/{set_name}/{label}\"\n",
        "        try:\n",
        "            number_of_files = len(os.listdir(path))\n",
        "            print(f\"There are {number_of_files} images in {set_name}/{label}\")\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Error: Directory '{path}' not found.\")\n",
        "\n",
        "# Compute total number of images across all datasets (train, validation, test)\n",
        "total_images = 0\n",
        "for set_name in sets:\n",
        "    for label in labels:\n",
        "        path = f\"inputs/mildew_dataset/cherry-leaves/{set_name}/{label}\"\n",
        "        try:\n",
        "            total_images += len(os.listdir(path))\n",
        "        except FileNotFoundError:\n",
        "            pass\n",
        "print(f\"\\nTotal number of images: {total_images}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "base_dir = \"inputs/mildew_dataset/cherry-leaves\"\n",
        "\n",
        "for subset in ['train', 'validation', 'test']:\n",
        "    print(f\"\\nğŸ“‚ {subset} ã‚»ãƒƒãƒˆ:\")\n",
        "    for label in os.listdir(os.path.join(base_dir, subset)):\n",
        "        count = len(os.listdir(os.path.join(base_dir, subset, label)))\n",
        "        print(f\"  - {label}: {count} æš\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… .ipynb ä»¥å¤–ã®ã™ã¹ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¨ inputs/ ãƒ•ã‚©ãƒ«ãƒ€ã‚’å‰Šé™¤ã—ã¾ã—ãŸï¼\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "\n",
        "# ğŸ“Œ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆcherry-leaf-disease-controlï¼‰\n",
        "root_dir = os.getcwd()  # ç¾åœ¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª\n",
        "\n",
        "# ğŸ“Œ .ipynb ä»¥å¤–ã®ã™ã¹ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤\n",
        "for file_path in glob.glob(os.path.join(root_dir, \"*\")):\n",
        "    if not file_path.endswith(\".ipynb\"):  # .ipynb ä»¥å¤–ã‚’å‰Šé™¤\n",
        "        try:\n",
        "            if os.path.isfile(file_path):\n",
        "                os.remove(file_path)  # ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤\n",
        "            elif os.path.isdir(file_path) and file_path.endswith(\"inputs\"):\n",
        "                shutil.rmtree(file_path)  # inputs ãƒ•ã‚©ãƒ«ãƒ€ã‚’å‰Šé™¤\n",
        "        except Exception as e:\n",
        "            print(f\"âš  å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {file_path} - {e}\")\n",
        "\n",
        "# ğŸ“Œ ç©ºã®ãƒ•ã‚©ãƒ«ãƒ€ã‚’å‰Šé™¤\n",
        "for dirpath, dirnames, filenames in os.walk(root_dir, topdown=False):\n",
        "    for dirname in dirnames:\n",
        "        dir_to_remove = os.path.join(dirpath, dirname)\n",
        "        if not os.listdir(dir_to_remove):  # ãƒ•ã‚©ãƒ«ãƒ€ãŒç©ºãªã‚‰å‰Šé™¤\n",
        "            os.rmdir(dir_to_remove)\n",
        "\n",
        "print(\"âœ… .ipynb ä»¥å¤–ã®ã™ã¹ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¨ inputs/ ãƒ•ã‚©ãƒ«ãƒ€ã‚’å‰Šé™¤ã—ã¾ã—ãŸï¼\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
