{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **(Data Visualization)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set Input Directories\n",
        "my_data_dir = 'inputs/mildew_dataset/cherry-leaves'\n",
        "train_path = my_data_dir + '/train'\n",
        "val_path = my_data_dir + '/validation'\n",
        "test_path = my_data_dir + '/test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®è¨­å®šï¼ˆGoogle Colabã§ã¯ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰é–‹å§‹ã™ã‚‹ã“ã¨ãŒå¤šã„ï¼‰\n",
        "work_dir = \"/content\"\n",
        "\n",
        "# å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹\n",
        "output_dir = os.path.join(work_dir, 'outputs')\n",
        "version = \"v1.0\"  # ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã®ãŸã‚ã®ãƒ•ã‚©ãƒ«ãƒ€å\n",
        "\n",
        "# å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "file_path = os.path.join(output_dir, version)\n",
        "\n",
        "# æ—¢ã«ãƒ•ã‚©ãƒ«ãƒ€ãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯\n",
        "if 'outputs' in os.listdir(work_dir) and version in os.listdir(output_dir):\n",
        "    print('Old version is already available. Create a new version.')\n",
        "else:\n",
        "    print(f'Creating new version directory: {file_path}')\n",
        "    os.makedirs(file_path, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’è¨­å®š\n",
        "train_path = \"/content/inputs/mildew_dataset/cherry-leaves/train\"\n",
        "\n",
        "# ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª\n",
        "if os.path.exists(train_path):\n",
        "    labels = os.listdir(train_path)\n",
        "    print('âœ… Label for the images are:', labels)\n",
        "else:\n",
        "    print(f\"âš  ã‚¨ãƒ©ãƒ¼: '{train_path}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Image Shape\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from imageio import imread  # ç”»åƒèª­ã¿è¾¼ã¿ç”¨\n",
        "\n",
        "# è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®ãƒ‘ã‚¹\n",
        "train_path = \"/content/inputs/mildew_dataset/cherry-leaves/train\"\n",
        "\n",
        "# ç”»åƒã®å¹³å‡ã‚µã‚¤ã‚ºã‚’è¨ˆç®—\n",
        "dim1, dim2 = [], []\n",
        "if os.path.exists(train_path):\n",
        "    labels = os.listdir(train_path)\n",
        "\n",
        "    for label in labels:\n",
        "        label_dir = os.path.join(train_path, label)\n",
        "        for image_filename in os.listdir(label_dir):\n",
        "            image_path = os.path.join(label_dir, image_filename)\n",
        "            try:\n",
        "                img = imread(image_path)\n",
        "                d1, d2, _ = img.shape  # é«˜ã•ãƒ»å¹…ãƒ»è‰²ãƒãƒ£ãƒãƒ«æ•°\n",
        "                dim1.append(d1)  # é«˜ã•\n",
        "                dim2.append(d2)  # å¹…\n",
        "            except Exception as e:\n",
        "                print(f\"âš  ç”»åƒèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {image_path}, {e}\")\n",
        "\n",
        "    # Seabornã®ã‚¹ã‚¿ã‚¤ãƒ«è¨­å®š\n",
        "    sns.set_style(\"whitegrid\")\n",
        "    fig, axes = plt.subplots()\n",
        "\n",
        "    # ç”»åƒã®ã‚µã‚¤ã‚ºã‚’æ•£å¸ƒå›³ã¨ã—ã¦ãƒ—ãƒ­ãƒƒãƒˆ\n",
        "    sns.scatterplot(x=dim2, y=dim1, alpha=0.2)\n",
        "    axes.set_xlabel(\"Width (pixels)\")\n",
        "    axes.set_ylabel(\"Height (pixels)\")\n",
        "\n",
        "    # å¹³å‡ã‚µã‚¤ã‚ºã‚’è¨ˆç®—\n",
        "    dim1_mean = int(np.mean(dim1))\n",
        "    dim2_mean = int(np.mean(dim2))\n",
        "\n",
        "    # å¹³å‡å€¤ã®ç·šã‚’æç”»\n",
        "    axes.axvline(x=dim2_mean, color='r', linestyle='--')\n",
        "    axes.axhline(y=dim1_mean, color='r', linestyle='--')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    # å¹³å‡ã‚µã‚¤ã‚ºã‚’å‡ºåŠ›\n",
        "    print(f\"ğŸ“ å¹³å‡ Width: {dim2_mean}px \\nğŸ“ å¹³å‡ Height: {dim1_mean}px\")\n",
        "\n",
        "else:\n",
        "    print(f\"âš  ã‚¨ãƒ©ãƒ¼: '{train_path}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image_shape = (128, 128, 3)\n",
        "image_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import joblib\n",
        "\n",
        "file_path = \"/content/outputs/v1.0\"\n",
        "\n",
        "# âœ… ã‚‚ã— `image_shape.pkl` ãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯å‰Šé™¤\n",
        "if os.path.exists(f\"{file_path}/image_shape.pkl\"):\n",
        "    os.remove(f\"{file_path}/image_shape.pkl\")\n",
        "    print(\"ğŸ—‘ï¸ `image_shape.pkl` ã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚\")\n",
        "\n",
        "# âœ… æ­£ã—ã„ `image_shape` ã‚’ (128, 128) ã§ä¿å­˜\n",
        "image_shape = (128, 128)  # ä¿®æ­£: ã‚¿ãƒ—ãƒ«å½¢å¼ã§ä¿å­˜\n",
        "joblib.dump(value=image_shape, filename=f\"{file_path}/image_shape.pkl\")\n",
        "\n",
        "print(f\"âœ… `image_shape.pkl` ã‚’æ­£ã—ã„å½¢å¼ã§ä¿å­˜ã—ã¾ã—ãŸ: {image_shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# âœ… `image_shape.pkl` ã‚’ãƒ­ãƒ¼ãƒ‰\n",
        "image_shape = joblib.load(f\"{file_path}/image_shape.pkl\")\n",
        "\n",
        "print(\"ãƒ­ãƒ¼ãƒ‰ã—ãŸ image_shape:\", image_shape)\n",
        "print(\"image_shapeã®å‹:\", type(image_shape))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª\n",
        "my_data_dir = \"/content/inputs/mildew_dataset/cherry-leaves\"\n",
        "\n",
        "# å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹ï¼ˆGoogle Colabç”¨ï¼‰\n",
        "file_path = \"/content/outputs/v1.0\"\n",
        "os.makedirs(file_path, exist_ok=True)  # ãƒ•ã‚©ãƒ«ãƒ€ãŒãªã„å ´åˆã¯ä½œæˆ\n",
        "\n",
        "# ã‚¯ãƒ©ã‚¹ãƒ©ãƒ™ãƒ«ã®å–å¾—ï¼ˆtrainã‚»ãƒƒãƒˆã‹ã‚‰å–å¾—ï¼‰\n",
        "labels = os.listdir(os.path.join(my_data_dir, \"train\"))\n",
        "\n",
        "# 2. ã‚¯ãƒ©ã‚¹åˆ†å¸ƒ (Training, Validation, Test)\n",
        "data = {\"Set\": [], \"Label\": [], \"Frequency\": []}  # ä¿®æ­£\n",
        "\n",
        "folders = [\"train\", \"validation\", \"test\"]\n",
        "\n",
        "for folder in folders:\n",
        "    for label in labels:\n",
        "        label_path = os.path.join(my_data_dir, folder, label)\n",
        "        frequency = len(os.listdir(label_path))\n",
        "        data[\"Set\"].append(folder)\n",
        "        data[\"Label\"].append(label)\n",
        "        data[\"Frequency\"].append(frequency)\n",
        "        print(f\"âœ… {folder} - {label}: {frequency} images\")\n",
        "\n",
        "# Pandasãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¤‰æ›\n",
        "df_freq = pd.DataFrame(data)\n",
        "\n",
        "# ã‚¯ãƒ©ã‚¹åˆ†å¸ƒã‚’ãƒ—ãƒ­ãƒƒãƒˆ\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.barplot(data=df_freq, x=\"Set\", y=\"Frequency\", hue=\"Label\")\n",
        "plt.title(\"Class Distribution Across Datasets (for Balance Check)\")  # ç›®çš„ã‚’è¿½åŠ \n",
        "plt.savefig(f\"{file_path}/class_distribution.png\")  # ã‚°ãƒ©ãƒ•ã‚’ä¿å­˜\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Average and Variability of Images Per Label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "\n",
        "def load_image_as_array(my_data_dir, new_size=(50, 50), n_images_per_label=20):\n",
        "    \"\"\"\n",
        "    Loads images from a directory, resizes them, and returns them as arrays with labels.\n",
        "\n",
        "    Parameters:\n",
        "    - my_data_dir (str): Path to the dataset directory with subfolders for each label.\n",
        "    - new_size (tuple): Target size for resizing images (default: (50, 50)).\n",
        "    - n_images_per_label (int): Max number of images to load per label (default: 20).\n",
        "\n",
        "    Returns:\n",
        "    - X (numpy.ndarray): Array of resized image data.\n",
        "    - y (numpy.ndarray): Array of corresponding labels.\n",
        "    \"\"\"\n",
        "\n",
        "    X, y = np.array([], dtype=\"int\"), np.array([], dtype=\"object\")\n",
        "    labels = os.listdir(my_data_dir)\n",
        "\n",
        "    for label in labels:\n",
        "        counter = 0\n",
        "        for image_filename in os.listdir(my_data_dir + \"/\" + label):\n",
        "            if counter < n_images_per_label:\n",
        "\n",
        "                img = image.load_img(\n",
        "                    my_data_dir + \"/\" + label + \"/\" + image_filename,\n",
        "                    target_size=new_size,\n",
        "                )\n",
        "                if image.img_to_array(img).max() > 1:\n",
        "                    img_resized = image.img_to_array(img) / 255\n",
        "                else:\n",
        "                    img_resized = image.img_to_array(img)\n",
        "\n",
        "                X = np.append(X, img_resized).reshape(\n",
        "                    -1, new_size[0], new_size[1], img_resized.shape[2]\n",
        "                )\n",
        "                y = np.append(y, label)\n",
        "                counter += 1\n",
        "\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X, y = load_image_as_array(\n",
        "    my_data_dir=train_path,\n",
        "    new_size=image_shape,  # âœ… (128, 128) ã®ã‚¿ãƒ—ãƒ«ã‚’æ¸¡ã™\n",
        "    n_images_per_label=30,\n",
        ")\n",
        "\n",
        "print(\"Xã®å½¢çŠ¶:\", X.shape)\n",
        "print(\"yã®å½¢çŠ¶:\", y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"image_shape:\", image_shape)\n",
        "print(\"image_shapeã®å‹:\", type(image_shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_mean_variability_per_labels(X, y, figsize=(12, 5), save_image=False):\n",
        "    \"\"\"\n",
        "    The pseudo-code for the function is:\n",
        "    * Iterate through all unique labels in the dataset.\n",
        "    * Filter the dataset to include only images corresponding to the current label.\n",
        "    * Calculate the mean and standard deviation for the filtered subset.\n",
        "    * Create a figure with two subplots:\n",
        "        - One displaying the mean image for the label.\n",
        "        - The other showing the variability (standard deviation) image.\n",
        "    * Optionally save the generated plots to the specified directory.\n",
        "    \"\"\"\n",
        "\n",
        "    for label_to_display in np.unique(y):\n",
        "        sns.set_style(\"white\")  # Set the plot style\n",
        "\n",
        "        # Reshape labels for compatibility and filter images for the current label\n",
        "        y = y.reshape(-1, 1, 1)\n",
        "        boolean_mask = np.any(y == label_to_display, axis=1).reshape(-1)\n",
        "        arr = X[boolean_mask]\n",
        "\n",
        "        # Compute the mean and variability for the current label\n",
        "        avg_img = np.mean(arr, axis=0)\n",
        "        std_img = np.std(arr, axis=0)\n",
        "        print(f\"==== Label {label_to_display} ====\")\n",
        "        print(f\"Image Shape: {avg_img.shape}\")\n",
        "\n",
        "        # Create a figure to display the average and variability images\n",
        "        fig, axes = plt.subplots(nrows=1, ncols=2, figsize=figsize)\n",
        "        axes[0].set_title(f\"Average image for label {label_to_display}\")\n",
        "        axes[0].imshow(avg_img, cmap=\"gray\")\n",
        "        axes[1].set_title(f\"Variability image for label {label_to_display}\")\n",
        "        axes[1].imshow(std_img, cmap=\"gray\")\n",
        "\n",
        "        # Save or display the figure based on the `save_image` argument\n",
        "        if save_image:\n",
        "            plt.savefig(\n",
        "                f\"{file_path}/avg_var_{label_to_display}.png\",\n",
        "                bbox_inches=\"tight\",\n",
        "                dpi=150,\n",
        "            )\n",
        "        else:\n",
        "            plt.tight_layout()  # Adjust layout for better spacing\n",
        "            plt.show()\n",
        "            print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_mean_variability_per_labels(X=X, y=y, figsize=(12, 5), save_image=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def subset_image_label(X, y, label_to_display):\n",
        "    \"\"\"\n",
        "    Filters the dataset to include only the images that belong to a specific label.\n",
        "    \"\"\"\n",
        "\n",
        "    # Reshape the labels for compatibility and filter for the given label\n",
        "    y = y.reshape(-1, 1, 1)\n",
        "    y = y.reshape(-1, 1, 1)\n",
        "    boolean_mask = np.any(y == label_to_display, axis=1).reshape(-1)\n",
        "    df = X[boolean_mask]  # Subset the dataset\n",
        "    return df\n",
        "\n",
        "\n",
        "def diff_bet_avg_image_labels_data_as_array(\n",
        "    X, y, label_1, label_2, figsize=(20, 5), save_image=False\n",
        "):\n",
        "    \"\"\"\n",
        "    Compares the average images between two specified labels.\n",
        "\n",
        "    - Verifies that both labels exist in the dataset.\n",
        "    - Calculates the mean image for each label.\n",
        "    - Computes the difference between the two mean images.\n",
        "    - Displays or optionally saves a figure with:\n",
        "        * Average image for label_1\n",
        "        * Average image for label_2\n",
        "        * Difference between the two averages\n",
        "    \"\"\"\n",
        "    sns.set_style(\"white\")\n",
        "\n",
        "    # Validate that both labels are present in the dataset\n",
        "    if (label_1 not in np.unique(y)) or (label_2 not in np.unique(y)):\n",
        "        print(f\"Either label {label} or label {label_2}, are not in {np.unique(y)} \")\n",
        "        return\n",
        "\n",
        "    # Calculate mean from label_1\n",
        "    images_label = subset_image_label(X, y, label_1)\n",
        "    label1_avg = np.mean(images_label, axis=0)\n",
        "    # Calculate mean from label_2\n",
        "    images_label = subset_image_label(X, y, label_2)\n",
        "    label2_avg = np.mean(images_label, axis=0)\n",
        "\n",
        "    # Compute the difference between the two mean images\n",
        "    difference_mean = label1_avg - label2_avg\n",
        "\n",
        "    # Create and display a plot with the results\n",
        "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=figsize)\n",
        "    axes[0].imshow(label1_avg, cmap=\"gray\")\n",
        "    axes[0].set_title(f\"Average {label_1}\")\n",
        "    axes[1].imshow(label2_avg, cmap=\"gray\")\n",
        "    axes[1].set_title(f\"Average {label_2}\")\n",
        "    axes[2].imshow(difference_mean, cmap=\"gray\")\n",
        "    axes[2].set_title(f\"Difference image: Avg {label_1} & {label_2}\")\n",
        "\n",
        "    # Save the plot to a file if save_image=True, otherwise display it\n",
        "    if save_image:\n",
        "        plt.savefig(f\"{file_path}/avg_diff.png\", bbox_inches=\"tight\", dpi=150)\n",
        "    else:\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "diff_bet_avg_image_labels_data_as_array(\n",
        "    X=X, y=y, label_1=\"Healthy\", label_2=\"Infected\", figsize=(12, 10), save_image=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Image Montage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import itertools\n",
        "import random\n",
        "\n",
        "sns.set_style(\"white\")\n",
        "\n",
        "\n",
        "def image_montage(dir_path, label_to_display, nrows, ncols, figsize=(15, 10)):\n",
        "    \"\"\"\n",
        "    - Verify if the specified label exists in the directory.\n",
        "    - Ensure the grid size (nrows * ncols) does not exceed the number of available images.\n",
        "    - Generate a list of indices for placing images in the grid based on the specified rows and columns.\n",
        "    - Create a figure to display the images, loading and plotting each in the respective grid space.\n",
        "    \"\"\"\n",
        "\n",
        "    labels = os.listdir(dir_path)\n",
        "\n",
        "    # Check if the specified label exists in the directory\n",
        "    if label_to_display in labels:\n",
        "\n",
        "        # Validate that the montage grid can fit the available images\n",
        "        images_list = os.listdir(dir_path + \"/\" + label_to_display)\n",
        "        if nrows * ncols < len(images_list):\n",
        "            img_idx = random.sample(images_list, nrows * ncols)\n",
        "        else:\n",
        "            print(\n",
        "                f\"Reduce the number of rows or columns for the montage. \\n\"\n",
        "                f\"There are only {len(images_list)} images available. \"\n",
        "                f\"You requested a grid for {nrows * ncols} images.\"\n",
        "            )\n",
        "            return\n",
        "\n",
        "        # Generate grid indices based on the number of rows and columns\n",
        "        list_rows = range(0, nrows)\n",
        "        list_cols = range(0, ncols)\n",
        "        plot_idx = list(itertools.product(list_rows, list_cols))\n",
        "\n",
        "        # Create a figure and populate it with the selected images\n",
        "        fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=figsize)\n",
        "        for x in range(0, nrows * ncols):\n",
        "            img = imread(dir_path + \"/\" + label_to_display + \"/\" + img_idx[x])\n",
        "            img_shape = img.shape\n",
        "            axes[plot_idx[x][0], plot_idx[x][1]].imshow(img)\n",
        "            axes[plot_idx[x][0], plot_idx[x][1]].set_title(\n",
        "                f\"Width: {img_shape[1]}px, Height: {img_shape[0]}px\"\n",
        "            )\n",
        "            axes[plot_idx[x][0], plot_idx[x][1]].set_xticks([])\n",
        "            axes[plot_idx[x][0], plot_idx[x][1]].set_yticks([])\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    else:\n",
        "        # Notify the user if the selected label does not exist\n",
        "        print(f\"The selected label '{label_to_display}' does not exist.\")\n",
        "        print(f\"Available labels are: {labels}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for label in labels:\n",
        "    print(label)\n",
        "    image_montage(\n",
        "        dir_path=train_path, label_to_display=label, nrows=3, ncols=3, figsize=(10, 15)\n",
        "    )\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Healthy VS Infected Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def compare_healthy_infected(X, y, n_images=5):\n",
        "    \"\"\"Healthy ã¨ Infected ã®ç”»åƒã‚’ä¸¦ã¹ã¦æ¯”è¼ƒ\"\"\"\n",
        "\n",
        "    # âœ… `y` ãŒ `0` / `1` ã®å ´åˆã€ãƒ©ãƒ™ãƒ«ã‚’å¤‰æ›\n",
        "    if np.issubdtype(y.dtype, np.number):  # y ãŒæ•°å€¤å‹ãªã‚‰\n",
        "        label_map = {0: \"Healthy\", 1: \"Infected\"}\n",
        "        y = np.array([label_map[label] for label in y])\n",
        "\n",
        "    # âœ… ã‚¯ãƒ©ã‚¹ã”ã¨ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—\n",
        "    healthy_indices = np.where(y == \"Healthy\")[0]\n",
        "    infected_indices = np.where(y == \"Infected\")[0]\n",
        "\n",
        "    # âœ… `n_images` ã‚’ãƒ‡ãƒ¼ã‚¿æ•°ã«åˆã‚ã›ã‚‹\n",
        "    n_images = min(n_images, len(healthy_indices), len(infected_indices))\n",
        "\n",
        "    # âœ… ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’ `[0,255]` ã®ç¯„å›²ã«ã‚¹ã‚±ãƒ¼ãƒ«å¤‰æ› (çœŸã£é»’å›é¿)\n",
        "    if X.max() <= 1.0:  # ã‚‚ã— `X` ã®å€¤ãŒ `[0,1]` ã®ç¯„å›²ãªã‚‰ `[0,255]` ã«å¤‰æ›\n",
        "        X = (X * 255).astype(np.uint8)\n",
        "\n",
        "    # âœ… ç”»åƒã‚’ä¸¦ã¹ã¦è¡¨ç¤º\n",
        "    for i in range(n_images):\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
        "\n",
        "        # ç”»åƒã‚’å–å¾—\n",
        "        healthy_image = X[healthy_indices[i]]\n",
        "        infected_image = X[infected_indices[i]]\n",
        "\n",
        "        # ç”»åƒã‚’è¡¨ç¤º\n",
        "        axes[0].imshow(healthy_image)\n",
        "        axes[0].set_title(\"Healthy\")\n",
        "        axes[0].axis(\"off\")\n",
        "\n",
        "        axes[1].imshow(infected_image)\n",
        "        axes[1].set_title(\"Infected\")\n",
        "        axes[1].axis(\"off\")\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "# âœ… ä¿®æ­£å¾Œã®é–¢æ•°ã‚’å®Ÿè¡Œ\n",
        "compare_healthy_infected(X, y)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
