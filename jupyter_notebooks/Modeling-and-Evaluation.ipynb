{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **(Modeling & Evaluation)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Number of images in train, test, validation data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ✅ クラスラベルを明示的に定義\n",
        "labels = ['Healthy', 'Infected']\n",
        "\n",
        "# ✅ データを保存する辞書を作成\n",
        "data = {\n",
        "    'Set': [],\n",
        "    'Label': [],\n",
        "    'Frequency': []\n",
        "}\n",
        "\n",
        "# ✅ データセットフォルダリスト\n",
        "folders = ['train', 'validation', 'test']\n",
        "\n",
        "# ✅ 各フォルダとラベルごとに画像の数をカウント\n",
        "for folder in folders:\n",
        "    for label in labels:\n",
        "        label_path = os.path.join(my_data_dir, folder, label)\n",
        "\n",
        "        # フォルダが存在するか確認 (もしデータがない場合のエラー防止)\n",
        "        if os.path.exists(label_path):\n",
        "            num_images = len(os.listdir(label_path))\n",
        "            data['Set'].append(folder)\n",
        "            data['Label'].append(label)\n",
        "            data['Frequency'].append(num_images)\n",
        "            print(f\"✅ {folder} - {label}: {num_images} images\")\n",
        "        else:\n",
        "            print(f\"⚠️ WARNING: {label_path} not found!\")\n",
        "\n",
        "# ✅ Pandas DataFrame に変換\n",
        "df_freq = pd.DataFrame(data)\n",
        "\n",
        "# ✅ クラス分布を可視化\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.barplot(data=df_freq, x='Set', y='Frequency', hue='Label')\n",
        "plt.title(\"Class Distribution in Train, Validation, and Test Sets\")  # タイトルを追加\n",
        "plt.savefig(f'{file_path}/labels_distribution.png', bbox_inches='tight', dpi=150)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Image Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Initialize image dat generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "augmented_image_data = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.10,\n",
        "    height_shift_range=0.10,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    fill_mode=\"nearest\",\n",
        "    rescale=1.0 / 255,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Augment train dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load training images with augmentation\n",
        "batch_size = 20  # Number of images processed in each batch\n",
        "train_set = augmented_image_data.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=image_shape[:2],\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"binary\",\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "# Print dataset information\n",
        "print(\"Class indices:\", train_set.class_indices)  # Dictionary mapping labels to indices\n",
        "print(\"Number of classes:\", len(train_set.class_indices))  # Total number of classes\n",
        "print(\n",
        "    \"Total number of images in dataset:\", train_set.samples\n",
        ")  # Total number of images (before augmentation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preprocessing the validation images: Normalize pixel values to the range [0, 1]\n",
        "validation_set = ImageDataGenerator(rescale=1.0 / 255).flow_from_directory(\n",
        "    val_path,\n",
        "    target_size=image_shape[:2],\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"binary\",\n",
        "    shuffle=False,\n",
        ")\n",
        "\n",
        "# Display class indices (label mapping)\n",
        "print(validation_set.class_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preprocessing the test images: Normalize pixel values to the range [0, 1]\n",
        "test_set = ImageDataGenerator(rescale=1.0 / 255).flow_from_directory(\n",
        "    test_path,\n",
        "    target_size=image_shape[:2],\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"binary\",\n",
        "    shuffle=False,\n",
        ")\n",
        "\n",
        "# Display class indices (label mapping)\n",
        "print(test_set.class_indices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot augmented training images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for _ in range(3):\n",
        "    img, label = next(train_set)\n",
        "    print(img.shape)  # (1,256,256,3)\n",
        "    plt.imshow(img[0])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot augmented validatation images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for _ in range(3):\n",
        "    img, label = next(validation_set)\n",
        "    print(img.shape)  # (1,256,256,3)\n",
        "    plt.imshow(img[0])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for _ in range(3):\n",
        "    img, label = next(test_set)\n",
        "    print(img.shape)  # (1,256,256,3)\n",
        "    plt.imshow(img[0])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Save class_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "joblib.dump(value=train_set.class_indices, filename=f\"{file_path}/class_indices.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Model Creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.utils.class_weight import compute_class_weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ✅ モデルの入力サイズ\n",
        "image_shape = (128, 128, 3)\n",
        "\n",
        "# ✅ モデルの保存先を定義\n",
        "output_path_cnn = \"outputs/v1.0\"\n",
        "os.makedirs(output_path_cnn, exist_ok=True)  # `outputs/v1.0/` を作成\n",
        "\n",
        "\n",
        "# ✅ 初期の CNN モデルを再構築\n",
        "def create_tf_model():\n",
        "    \"\"\"\n",
        "    Build a CNN model with convolution, pooling, and dropout layers.\n",
        "    \"\"\"\n",
        "    model = Sequential(\n",
        "        [\n",
        "            Conv2D(\n",
        "                filters=32,\n",
        "                kernel_size=(3, 3),\n",
        "                activation=\"relu\",\n",
        "                input_shape=image_shape,\n",
        "            ),\n",
        "            MaxPooling2D(pool_size=(2, 2)),\n",
        "            Conv2D(filters=64, kernel_size=(3, 3), activation=\"relu\"),\n",
        "            MaxPooling2D(pool_size=(2, 2)),\n",
        "            Conv2D(filters=128, kernel_size=(3, 3), activation=\"relu\"),\n",
        "            MaxPooling2D(pool_size=(2, 2)),\n",
        "            Conv2D(filters=128, kernel_size=(3, 3), activation=\"relu\"),\n",
        "            MaxPooling2D(pool_size=(2, 2)),\n",
        "            Flatten(),\n",
        "            Dense(128, activation=\"relu\"),\n",
        "            Dropout(0.3),\n",
        "            Dense(1, activation=\"sigmoid\"),  # 2クラス分類\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # ✅ `Adam` オプティマイザの学習率をそのまま使用\n",
        "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# ✅ `cnn_model` を作成\n",
        "cnn_model = create_tf_model()\n",
        "\n",
        "# ✅ モデルの構造を確認\n",
        "cnn_model.summary()\n",
        "\n",
        "print(\"✅ `cnn_model` の修正 & 再作成が完了しました！\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Early stopping\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stop = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### モデルの学習"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = create_tf_model()\n",
        "model.fit(\n",
        "    train_set,\n",
        "    epochs=25,\n",
        "    steps_per_epoch=len(train_set.classes) // batch_size,\n",
        "    validation_data=validation_set,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save Model\n",
        "\n",
        "output_path_cnn = \"outputs/v1.0\"\n",
        "os.makedirs(output_path_cnn, exist_ok=True)  # ✅ `outputs/v1.0/` を作成\n",
        "\n",
        "cnn_model.save(f\"{output_path_cnn}/mildew_detector_model.keras\")\n",
        "print(\n",
        "    f\"✅ CNN モデルのトレーニングと保存が完了しました！\\nモデルの保存先: {output_path_cnn}/mildew_detector_model.keras\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Learning Curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# ✅ 適切な保存ディレクトリを指定\n",
        "save_dir = \"outputs/v1.0\"  # ここを `mildew_detector_model.keras` ではなくフォルダにする\n",
        "os.makedirs(save_dir, exist_ok=True)  # ディレクトリがない場合は作成\n",
        "\n",
        "# ✅ `model.history.history` から DataFrame を作成\n",
        "losses = pd.DataFrame(model.history.history)\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "# ✅ Loss のプロット\n",
        "losses[[\"loss\", \"val_loss\"]].plot(style=\".-\")\n",
        "plt.title(\"Loss\")\n",
        "plt.savefig(f\"{save_dir}/model_training_losses.png\", bbox_inches=\"tight\", dpi=150)\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "# ✅ Accuracy のプロット\n",
        "losses[[\"accuracy\", \"val_accuracy\"]].plot(style=\".-\")\n",
        "plt.title(\"Accuracy\")\n",
        "plt.savefig(f\"{save_dir}/model_training_acc.png\", bbox_inches=\"tight\", dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model = load_model(\"outputs/v1.0/mildew_detector_model.keras\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluate Model on Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluation = model.evaluate(test_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "joblib.dump(value=evaluation, filename=f\"outputs/v1.0/evaluation.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Confusion Matrix & Classification Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# ✅ 適切なディレクトリに変更\n",
        "save_dir = \"outputs/v1.0\"  # `file_path` を `save_dir` に修正\n",
        "os.makedirs(save_dir, exist_ok=True)  # ディレクトリがない場合は作成\n",
        "\n",
        "# ✅ 予測を取得\n",
        "y_pred = model.predict(test_set)\n",
        "\n",
        "# ✅ バイナリ分類か多クラス分類かを判定し、適切な処理を行う\n",
        "if y_pred.shape[1] == 1:  # バイナリ分類の場合\n",
        "    y_pred = (y_pred > 0.5).astype(int).flatten()\n",
        "else:  # 多クラス分類の場合\n",
        "    y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# ✅ 正解ラベルを取得\n",
        "y_true = test_set.classes\n",
        "\n",
        "# ✅ Classification Report の表示\n",
        "print(\"Classification Report:\\n\")\n",
        "print(classification_report(y_true, y_pred, target_names=[\"Healthy\", \"Infected\"]))\n",
        "\n",
        "# ✅ Confusion Matrix の計算\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# ✅ Confusion Matrix の可視化\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(\n",
        "    cm,\n",
        "    annot=True,\n",
        "    fmt=\"d\",\n",
        "    cmap=\"Blues\",\n",
        "    xticklabels=[\"Healthy\", \"Infected\"],\n",
        "    yticklabels=[\"Healthy\", \"Infected\"],\n",
        ")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "\n",
        "# ✅ Confusion Matrix の保存 (修正後)\n",
        "plt.savefig(f\"{save_dir}/confusion_matrix.png\", bbox_inches=\"tight\", dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "モデルの構築　CNN-MobileNetV2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# ✅ 新しいバージョンのフォルダ (`outputs/v1.1/`) を作成\n",
        "version = \"v1.1\"  # ここでバージョンを変更\n",
        "output_path = f\"outputs/{version}\"\n",
        "os.makedirs(output_path, exist_ok=True)  # フォルダが存在しない場合は作成\n",
        "\n",
        "# ✅ MobileNetV2 のベースモデルをロード (事前学習済みの重みを使用)\n",
        "base_model = MobileNetV2(\n",
        "    weights=\"imagenet\", include_top=False, input_shape=(128, 128, 3)\n",
        ")\n",
        "\n",
        "# ✅ 最初の層は固定し、一部の層は学習可能にする\n",
        "for layer in base_model.layers[:-20]:  # 最初の層は固定\n",
        "    layer.trainable = False\n",
        "for layer in base_model.layers[-20:]:  # 後半の層を学習可能にする\n",
        "    layer.trainable = True\n",
        "\n",
        "# ✅ 新しい出力層を追加\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(128, activation=\"relu\")(x)\n",
        "x = Dense(64, activation=\"relu\")(x)\n",
        "output_layer = Dense(1, activation=\"sigmoid\")(x)  # 2クラス分類\n",
        "\n",
        "# ✅ モデルの構築\n",
        "mobilenet_model = Model(inputs=base_model.input, outputs=output_layer)\n",
        "\n",
        "# ✅ モデルのコンパイル\n",
        "mobilenet_model.compile(\n",
        "    optimizer=Adam(learning_rate=0.0001),\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "# ✅ モデルのサマリーを表示\n",
        "mobilenet_model.summary()\n",
        "\n",
        "print(\"✅ MobileNetV2 モデルを新しい学習率で再コンパイルしました！\")\n",
        "\n",
        "# ✅ EarlyStopping の設定\n",
        "early_stop = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
        "\n",
        "# ✅ モデルの学習\n",
        "history_mobilenet = mobilenet_model.fit(\n",
        "    train_set,\n",
        "    validation_data=validation_set,\n",
        "    epochs=25,\n",
        "    steps_per_epoch=len(train_set)\n",
        "    // train_set.batch_size,  # ✅ 修正: ステップ数を適切に計算\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_path_mobilenet = \"outputs/v1.1\"\n",
        "os.makedirs(output_path_mobilenet, exist_ok=True)  # ✅ `outputs/v1.1/` を作成\n",
        "\n",
        "mobilenet_model.save(f\"{output_path_mobilenet}/mildew_mobilenet_model.keras\")\n",
        "print(\n",
        "    f\"✅ MobileNetV2 モデルのトレーニングと保存が完了しました！\\nモデルの保存先: {output_path_mobilenet}/mildew_mobilenet_model.keras\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### モデルの評価（Accuracy & Loss）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# ✅ モデルをロード\n",
        "cnn_model = load_model(\"outputs/v1.0/mildew_detector_model.keras\")\n",
        "mobilenet_model = load_model(\"outputs/v1.1/mildew_mobilenet_model.keras\")\n",
        "\n",
        "# ✅ モデルの評価\n",
        "cnn_eval = cnn_model.evaluate(test_set, verbose=1)\n",
        "mobilenet_eval = mobilenet_model.evaluate(test_set, verbose=1)\n",
        "\n",
        "# ✅ 結果を表示\n",
        "print(f\"✅ CNN Model (v1.0) - Loss: {cnn_eval[0]:.4f}, Accuracy: {cnn_eval[1]:.4f}\")\n",
        "print(\n",
        "    f\"✅ MobileNetV2 Model (v1.1) - Loss: {mobilenet_eval[0]:.4f}, Accuracy: {mobilenet_eval[1]:.4f}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Confusion Matrix & Classification Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# ✅ 予測を取得\n",
        "cnn_preds = (cnn_model.predict(test_set) > 0.5).astype(int)\n",
        "mobilenet_preds = (mobilenet_model.predict(test_set) > 0.5).astype(int)\n",
        "\n",
        "# ✅ 正解ラベルを取得\n",
        "y_true = test_set.classes\n",
        "\n",
        "# ✅ Confusion Matrix の計算\n",
        "cnn_cm = confusion_matrix(y_true, cnn_preds)\n",
        "mobilenet_cm = confusion_matrix(y_true, mobilenet_preds)\n",
        "\n",
        "# ✅ Confusion Matrix の可視化 (CNN)\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(\n",
        "    cnn_cm,\n",
        "    annot=True,\n",
        "    fmt=\"d\",\n",
        "    cmap=\"Blues\",\n",
        "    xticklabels=[\"Healthy\", \"Infected\"],\n",
        "    yticklabels=[\"Healthy\", \"Infected\"],\n",
        ")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix - CNN (v1.0)\")\n",
        "plt.show()\n",
        "\n",
        "# ✅ Confusion Matrix の可視化 (MobileNetV2)\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(\n",
        "    mobilenet_cm,\n",
        "    annot=True,\n",
        "    fmt=\"d\",\n",
        "    cmap=\"Blues\",\n",
        "    xticklabels=[\"Healthy\", \"Infected\"],\n",
        "    yticklabels=[\"Healthy\", \"Infected\"],\n",
        ")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix - MobileNetV2 (v1.1)\")\n",
        "plt.show()\n",
        "\n",
        "# ✅ Classification Report の表示\n",
        "print(\"Classification Report - CNN Model:\\n\")\n",
        "print(classification_report(y_true, cnn_preds, target_names=[\"Healthy\", \"Infected\"]))\n",
        "\n",
        "print(\"\\nClassification Report - MobileNetV2 Model:\\n\")\n",
        "print(\n",
        "    classification_report(y_true, mobilenet_preds, target_names=[\"Healthy\", \"Infected\"])\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### モデルの可視化（Loss & Accuracyの推移）"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
